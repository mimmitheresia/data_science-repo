{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1c3db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://example.com\")\n",
    "print(r.status_code)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# install package direcly in notebook: %pip install requests-html\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def most_frequent_terms(df, column, top_n=10):\n",
    "    \"\"\"\n",
    "    Return the most frequent terms from a text column in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        column (str): Column name containing text.\n",
    "        top_n (int): Number of most frequent terms to return.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with term counts.\n",
    "    \"\"\"\n",
    "    # Join all text in column into one big string\n",
    "    text = \" \".join(df[column].astype(str).tolist())\n",
    "    \n",
    "    # Tokenize: lowercase words, only keep a–z characters\n",
    "    tokens = re.findall(r\"\\b[a-zA-ZåäöÅÄÖ]+\\b\", text.lower())\n",
    "    \n",
    "    # Count terms\n",
    "    counter = Counter(tokens)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    most_common = counter.most_common(top_n)\n",
    "    return pd.DataFrame(most_common, columns=[\"term\", \"count\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbe00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('../data/raw/jobs.csv')\n",
    "#raw_data = raw_data.loc[raw_data['site']=='Aliant']\n",
    "raw_data[['site', 'job_title','ingestion_ts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_group = raw_data.groupby(by=['site']).count()\n",
    "raw_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = most_frequent_terms(raw_data, \"job_title\", top_n=100)\n",
    "df.to_csv('most_frequent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_data = pd.read_csv('../data/bronze/jobs.csv')\n",
    "bronze_data[['site', 'job_title', 'ingestion_ts','work_location','link']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef754407",
   "metadata": {},
   "source": [
    "# Afry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a360b4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afry > Response: 200\n",
      "Afry > Nmr of scraped adds: 73\n",
      "Afry > Unloading data to ../data/raw/jobs.csv. Nmr of new added jobs:0\n",
      "Afry > Loading last scraped jobs, nr: 0\n",
      "Afry > Parsing bronze data: 0\n",
      "Afry > Unloading data to ../data/bronze/jobs.csv. Nmr of new added jobs:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.afry_scraper import AfryScraper\n",
    "afry = AfryScraper()\n",
    "response = afry.request_status()\n",
    "job_posts = afry.return_raw_job_posts_data(response)\n",
    "scraped_raw_data = afry.parse_raw_data(job_posts)\n",
    "old_raw_data = afry.read_stored_raw_data()\n",
    "\n",
    "new_raw_data = afry.return_new_rows(new_data=scraped_raw_data, old_data=old_raw_data)\n",
    "afry.unload_data(file_path = \"../data/raw/jobs.csv\", new_data = new_raw_data)\n",
    "\n",
    "new_raw_data = afry.load_last_added_raw_data()\n",
    "new_bronze_data = afry.parse_bronze_data(new_raw_data)\n",
    "afry.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=new_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43f825",
   "metadata": {},
   "source": [
    "# Aliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2738342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliant > Response: 200\n",
      "Aliant > Nmr of scraped adds: 6\n",
      "Aliant > Unloading data to ../data/raw/jobs.csv. Nmr of new added jobs:0\n",
      "Aliant > Loading last scraped jobs, nr: 0\n",
      "Aliant > Parsing bronze data: 0\n",
      "Aliant > Unloading data to ../data/bronze/jobs.csv. Nmr of new added jobs:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.aliant_scraper import AliantScraper\n",
    "aliant = AliantScraper()\n",
    "response = aliant.request_status()\n",
    "job_posts = aliant.return_raw_job_posts_data(response)\n",
    "scraped_raw_data = aliant.parse_raw_data(job_posts)\n",
    "old_raw_data = aliant.read_stored_raw_data()\n",
    "\n",
    "new_raw_data = aliant.return_new_rows(new_data=scraped_raw_data, old_data=old_raw_data)\n",
    "aliant.unload_data(file_path = \"../data/raw/jobs.csv\", new_data = new_raw_data)\n",
    "\n",
    "new_raw_data = aliant.load_last_added_raw_data()\n",
    "new_bronze_data = aliant.parse_bronze_data(new_raw_data)\n",
    "aliant.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=new_bronze_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de53a36",
   "metadata": {},
   "source": [
    "# Asociety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03886cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.asociety_scraper import ASocietyScraper\n",
    "asociety = ASocietyScraper()\n",
    "response = asociety.request_status()\n",
    "job_posts = asociety.return_raw_job_posts_data(response)\n",
    "scraped_raw_data = asociety.parse_raw_data(job_posts)\n",
    "old_raw_data = pd.read_csv(\"../data/raw/jobs.csv\")\n",
    "\n",
    "new_raw_data = asociety.return_new_rows(new_data=raw_data, old_data=old_raw_data)\n",
    "asociety.unload_data(file_path = \"../data/raw/jobs.csv\", new_data = new_raw_data)\n",
    "\n",
    "new_raw_data = asociety.load_last_added_raw_data()\n",
    "new_bronze_data = asociety.parse_bronze_data(new_raw_data)\n",
    "asociety.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=new_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997fee",
   "metadata": {},
   "source": [
    "# Combitech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.combitech_scraper import CombitechScraper\n",
    "combitech = CombitechScraper()\n",
    "response = await combitech.request_status()\n",
    "job_posts = combitech.return_raw_job_posts_data(response)\n",
    "raw_data = combitech.parse_raw_data(job_posts)\n",
    "combitech.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = combitech.load_last_added_raw_data()\n",
    "bronze_data = combitech.parse_bronze_data(last_raw_data)\n",
    "combitech.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2477b1",
   "metadata": {},
   "source": [
    "# Emagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.emagine_scraper import EmagineScraper\n",
    "emagine = EmagineScraper()\n",
    "response = emagine.request_status()\n",
    "job_posts = emagine.return_raw_job_posts_data(response)\n",
    "raw_data = emagine.parse_raw_data(job_posts)\n",
    "emagine.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = emagine.load_last_added_raw_data()\n",
    "bronze_data = emagine.parse_bronze_data(last_raw_data)\n",
    "emagine.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b478e0c",
   "metadata": {},
   "source": [
    "# Ework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.ework_scraper import EworkScraper\n",
    "ework = EworkScraper()\n",
    "response = ework.request_status()\n",
    "job_posts = ework.return_raw_job_posts_data(response)\n",
    "raw_data = ework.parse_raw_data(job_posts)\n",
    "ework.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = ework.load_last_added_raw_data()\n",
    "bronze_data = ework.parse_bronze_data(last_raw_data)\n",
    "ework.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544094",
   "metadata": {},
   "source": [
    "# Levigo \n",
    "(Inga uppdrag ute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d618eb0",
   "metadata": {},
   "source": [
    "# Nikita \n",
    "Hemsida som renderar innehållet via JavaScript efter att själva HTML:en har laddats. I detta fall hittar man inte hittar uppdragen i Fetch/XHR i nätverksinspektionen – själva jobblistan hämtas inte via ett öppet API som returnerar JSON, utan genereras dynamiskt i webbläsaren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.nikita_scraper import NikitaScraper\n",
    "nikita = NikitaScraper()\n",
    "response = await nikita.request_status()\n",
    "job_posts = nikita.return_raw_job_posts_data(response)\n",
    "raw_data = nikita.parse_raw_data(job_posts)\n",
    "nikita.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = nikita.load_last_added_raw_data()\n",
    "bronze_data = nikita.parse_bronze_data(last_raw_data)\n",
    "nikita.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4bddc",
   "metadata": {},
   "source": [
    "# Regent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.regent_scraper import RegentScraper\n",
    "regent = RegentScraper()\n",
    "response = await regent.request_status()\n",
    "job_posts = regent.return_raw_job_posts_data(response)\n",
    "raw_data = regent.parse_raw_data(job_posts)\n",
    "regent.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = regent.load_last_added_raw_data()\n",
    "bronze_data = regent.parse_bronze_data(last_raw_data)\n",
    "regent.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9aa324",
   "metadata": {},
   "source": [
    "# Updraged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.upgraded_scraper import UpgradedScraper\n",
    "upgraded = UpgradedScraper()\n",
    "response = await upgraded.request_status()\n",
    "job_posts = upgraded.return_raw_job_posts_data(response)\n",
    "raw_data = upgraded.parse_raw_data(job_posts)\n",
    "upgraded.unload_data(file_path = \"../data/raw/jobs.csv\", new_data=raw_data)\n",
    "last_raw_data = upgraded.load_last_added_raw_data()\n",
    "bronze_data = upgraded.parse_bronze_data(last_raw_data)\n",
    "upgraded.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
