{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://example.com\")\n",
    "print(r.status_code)\n",
    "\n",
    "# install package direcly in notebook: %pip install requests-html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510c284",
   "metadata": {},
   "source": [
    "### Utils  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def slugify_title_for_link(text: str) -> str:\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Replace & with 'and'\n",
    "    text = text.replace(\"&\", \"and\")\n",
    "    # Remove special chars ( ) / , . \n",
    "    text = re.sub(r\"[%()\\/,\\.]\", \"\", text)\n",
    "    #Remove åäö\n",
    "    text = re.sub(r\"[åäöÅÄÖ]\", \"\", text)\n",
    "    #Remove multiple whitespaces \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    # Replace whitespace with hyphens\n",
    "    text = re.sub(r\"\\s+\", \"-\", text)\n",
    "    # Remove multiple consecutive hyphens\n",
    "    text = text.replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    text = re.sub(r\"-+\", \"-\", text)\n",
    "   \n",
    "    # Strip leading/trailing hyphens\n",
    "    return text.strip(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef754407",
   "metadata": {},
   "source": [
    "# Afry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.afry_scraper import AfryScraper\n",
    "afry = AfryScraper()\n",
    "response = afry.request_status()\n",
    "job_posts = afry.return_raw_job_posts_data(response)\n",
    "raw_data = afry.parse_raw_data(job_posts)\n",
    "afry.unload_data(file_path = \"../data/raw/jobs.csv\", data=raw_data)\n",
    "last_raw_data = afry.load_last_added_raw_data()\n",
    "bronze_data = afry.parse_bronze_data(last_raw_data)\n",
    "afry.unload_data(file_path=\"../data/bronze/jobs.csv\", data=bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43f825",
   "metadata": {},
   "source": [
    "# Aliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2738342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliant > Response: 200\n",
      "Aliant > Nmr of scraped adds: 6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AbstractScraper.unload_data() got an unexpected keyword argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m job_posts = aliant.return_raw_job_posts_data(response)\n\u001b[32m     10\u001b[39m raw_data = aliant.parse_raw_data(job_posts)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43maliant\u001b[49m\u001b[43m.\u001b[49m\u001b[43munload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/raw/jobs.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m last_raw_data = aliant.load_last_added_raw_data()\n\u001b[32m     13\u001b[39m bronze_data = aliant.parse_bronze_data(last_raw_data)\n",
      "\u001b[31mTypeError\u001b[39m: AbstractScraper.unload_data() got an unexpected keyword argument 'data'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.aliant_scraper import AliantScraper\n",
    "aliant = AliantScraper()\n",
    "response = aliant.request_status()\n",
    "job_posts = aliant.return_raw_job_posts_data(response)\n",
    "raw_data = aliant.parse_raw_data(job_posts)\n",
    "aliant.unload_data(file_path = \"../data/raw/jobs.csv\", new_data = raw_data)\n",
    "last_raw_data = aliant.load_last_added_raw_data()\n",
    "bronze_data = aliant.parse_bronze_data(last_raw_data)\n",
    "aliant.unload_data(file_path=\"../data/bronze/jobs.csv\", new_data=bronze_data)\n",
    "last_raw_data\n",
    "\n",
    "#job_posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4f93a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>site_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>raw_payload</th>\n",
       "      <th>ingestion_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449555</td>\n",
       "      <td>Elektronikkonstruktör (Altium Designer)</td>\n",
       "      <td>{'AdID': 449555, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449553</td>\n",
       "      <td>Scala-utvecklare</td>\n",
       "      <td>{'AdID': 449553, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449546</td>\n",
       "      <td>Medior Project Manager</td>\n",
       "      <td>{'AdID': 449546, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448256</td>\n",
       "      <td>Computer Vision - Android Automotive</td>\n",
       "      <td>{'AdID': 448256, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448170</td>\n",
       "      <td>Utvecklare - MES-system</td>\n",
       "      <td>{'AdID': 448170, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>432534</td>\n",
       "      <td>Sitecore-utvecklare</td>\n",
       "      <td>{'AdID': 432534, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 11:06:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449555</td>\n",
       "      <td>Elektronikkonstruktör (Altium Designer)</td>\n",
       "      <td>{'AdID': 449555, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449553</td>\n",
       "      <td>Scala-utvecklare</td>\n",
       "      <td>{'AdID': 449553, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449546</td>\n",
       "      <td>Medior Project Manager</td>\n",
       "      <td>{'AdID': 449546, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448256</td>\n",
       "      <td>Computer Vision - Android Automotive</td>\n",
       "      <td>{'AdID': 448256, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448170</td>\n",
       "      <td>Utvecklare - MES-system</td>\n",
       "      <td>{'AdID': 448170, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>432534</td>\n",
       "      <td>Sitecore-utvecklare</td>\n",
       "      <td>{'AdID': 432534, 'Positions': 1, 'AdLogo': 'ht...</td>\n",
       "      <td>2025-09-12 14:17:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       site site_id                                job_title  \\\n",
       "0    Aliant  449555  Elektronikkonstruktör (Altium Designer)   \n",
       "1    Aliant  449553                         Scala-utvecklare   \n",
       "2    Aliant  449546                   Medior Project Manager   \n",
       "3    Aliant  448256     Computer Vision - Android Automotive   \n",
       "4    Aliant  448170                  Utvecklare - MES-system   \n",
       "5    Aliant  432534                      Sitecore-utvecklare   \n",
       "183  Aliant  449555  Elektronikkonstruktör (Altium Designer)   \n",
       "184  Aliant  449553                         Scala-utvecklare   \n",
       "185  Aliant  449546                   Medior Project Manager   \n",
       "186  Aliant  448256     Computer Vision - Android Automotive   \n",
       "187  Aliant  448170                  Utvecklare - MES-system   \n",
       "188  Aliant  432534                      Sitecore-utvecklare   \n",
       "\n",
       "                                           raw_payload         ingestion_ts  \n",
       "0    {'AdID': 449555, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "1    {'AdID': 449553, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "2    {'AdID': 449546, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "3    {'AdID': 448256, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "4    {'AdID': 448170, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "5    {'AdID': 432534, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 11:06:57  \n",
       "183  {'AdID': 449555, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  \n",
       "184  {'AdID': 449553, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  \n",
       "185  {'AdID': 449546, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  \n",
       "186  {'AdID': 448256, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  \n",
       "187  {'AdID': 448170, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  \n",
       "188  {'AdID': 432534, 'Positions': 1, 'AdLogo': 'ht...  2025-09-12 14:17:03  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../data/raw/jobs.csv')\n",
    "raw_data = raw_data.loc[raw_data['site']=='Aliant']\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a9ca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>site_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>ingestion_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449555</td>\n",
       "      <td>Elektronikkonstruktör (Altium Designer)</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449553</td>\n",
       "      <td>Scala-utvecklare</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>449546</td>\n",
       "      <td>Medior Project Manager</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448256</td>\n",
       "      <td>Computer Vision - Android Automotive</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>448170</td>\n",
       "      <td>Utvecklare - MES-system</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>432534</td>\n",
       "      <td>Sitecore-utvecklare</td>\n",
       "      <td>2025-09-12 11:45:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     site site_id                                job_title  \\\n",
       "0  Aliant  449555  Elektronikkonstruktör (Altium Designer)   \n",
       "1  Aliant  449553                         Scala-utvecklare   \n",
       "2  Aliant  449546                   Medior Project Manager   \n",
       "3  Aliant  448256     Computer Vision - Android Automotive   \n",
       "4  Aliant  448170                  Utvecklare - MES-system   \n",
       "5  Aliant  432534                      Sitecore-utvecklare   \n",
       "\n",
       "          ingestion_ts  \n",
       "0  2025-09-12 11:45:04  \n",
       "1  2025-09-12 11:45:04  \n",
       "2  2025-09-12 11:45:04  \n",
       "3  2025-09-12 11:45:04  \n",
       "4  2025-09-12 11:45:04  \n",
       "5  2025-09-12 11:45:04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_data = pd.read_csv('../data/bronze/jobs.csv')\n",
    "bronze_data = bronze_data.loc[bronze_data['site']=='Aliant']\n",
    "bronze_data[['site', 'site_id', 'job_title', 'ingestion_ts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de53a36",
   "metadata": {},
   "source": [
    "# Asociety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03886cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "\n",
    "from src.asociety_scraper import ASocietyScraper\n",
    "asociety = ASocietyScraper()\n",
    "response = asociety.request_status()\n",
    "job_posts = asociety.return_raw_job_posts_data(response)\n",
    "raw_data = asociety.parse_raw_data(job_posts)\n",
    "asociety.unload_data(file_path = \"../data/raw/jobs.csv\", data=raw_data)\n",
    "#last_raw_data = asociety.load_last_added_raw_data()\n",
    "#bronze_data = asociety.parse_bronze_data(last_raw_data)\n",
    "#asociety.unload_data(file_path=\"../data/bronze/jobs.csv\", data=bronze_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c91669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, re\n",
    "\n",
    "\n",
    "url = \"https://www.asocietygroup.com/sv/uppdrag?_rsc=9il7j\"\n",
    "r = requests.get(url)\n",
    "html = r.text\n",
    "\n",
    "pattern = r'(\\{.*?requisition_name.*?\\})'\n",
    "all_matches = re.findall(pattern, html, re.DOTALL)\n",
    "\n",
    "print(\"Number of matches:\", len(all_matches))\n",
    "print(all_matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "job_data = {'website':[], 'id':[], 'job_title':[], 'area':[], 'created':[], 'start_date': [], 'end_date':[], 'duration':[],'due_date': [],'work_location': [], 'work_type': [], 'link':[]}\n",
    "job_data_asociety = job_data\n",
    "\n",
    "def return_regex_string_match(search_pattern, html_string):\n",
    "    search_match = re.search(search_pattern, html_string, re.DOTALL)\n",
    "    \n",
    "    if search_match: \n",
    "        label = search_match.group(1) if search_match.group(1) else search_match.group(2)\n",
    "    else: \n",
    "        label = '-'\n",
    "    return label\n",
    "\n",
    "for i, html_job in enumerate(all_matches): \n",
    "# Regex pattern handles escaped quotes (\\\") or normal quotes (\")\n",
    "    pattern_id = r'\\\\\"abstract_id\\\\\":\\\\\"(.*?)\\\\\"|\\\"abstract_id\\\":\\\"(.*?)\\\"' \n",
    "    pattern_job_title = r'\\\\\"requisition_name\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_name\\\":\\\"(.*?)\\\"'\n",
    "    pattern_area = r'\\\\\"requisition_servicecategoryid\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_servicecategoryid\\\":\\\"(.*?)\\\"'\n",
    "    \n",
    "    pattern_created = r'\\\\\"requisition_publisheddateandtime\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_publisheddateandtime\\\":\\\"(.*?)\\\"'\n",
    "    pattern_start_date = r'\\\\\"requisition_startdate\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_startdate\\\":\\\"(.*?)\\\"'\n",
    "    pattern_due_date = r'\\\\\"requisition_offerduedate\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_offerduedate\\\":\\\"(.*?)\\\"'\n",
    "\n",
    "    pattern_work_location = r'\\\\\"requisition_locationid\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_locationid\\\":\\\"(.*?)\\\"'\n",
    "    pattern_work_type = r'\\\\\"requisition_remotework\\\\\":\\\\\"(.*?)\\\\\"|\\\"requisition_remotework\\\":\\\"(.*?)\\\"'\n",
    "    \n",
    "    id = return_regex_string_match(pattern_id, html_job)\n",
    "    job_title = return_regex_string_match(pattern_job_title, html_job)\n",
    "    area = return_regex_string_match(pattern_area, html_job)\n",
    "\n",
    "    created = return_regex_string_match(pattern_created, html_job)\n",
    "    start_date = return_regex_string_match(pattern_start_date, html_job)\n",
    "    due_date = return_regex_string_match(pattern_due_date, html_job)\n",
    "\n",
    "    work_location = return_regex_string_match(pattern_work_location, html_job)\n",
    "    work_type = return_regex_string_match(pattern_work_type, html_job)\n",
    "    link = f'https://www.asocietygroup.com/sv/uppdrag/{slugify_title_for_link(job_title)}-{id}'\n",
    "    \n",
    "    job_data_asociety['website'].append('ASociety')  \n",
    "    job_data_asociety['id'].append(id)\n",
    "    job_data_asociety['job_title'].append(job_title)\n",
    "    job_data_asociety['area'].append(area)\n",
    "    \n",
    "    job_data_asociety['created'].append(created)\n",
    "    job_data_asociety['start_date'].append(start_date)\n",
    "    job_data_asociety['end_date'].append(None)\n",
    "    job_data_asociety['duration'].append(None)\n",
    "    job_data_asociety['due_date'].append(due_date)\n",
    "    \n",
    "    job_data_asociety['work_location'].append(work_location)\n",
    "    job_data_asociety['work_type'].append(work_type)\n",
    "    job_data_asociety['link'].append(link)\n",
    "    \n",
    "    \n",
    "\n",
    "job_df = pd.DataFrame(job_data_asociety)\n",
    "job_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997fee",
   "metadata": {},
   "source": [
    "# Combitech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d611776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Jupyter kan du köra async direkt med \"await\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def scrape_combitech_jobs():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://www.combitech.se/karriar/lediga-jobb/\")\n",
    "        await page.wait_for_timeout(2000)  # ge JS tid att ladda\n",
    "        html = await page.content()\n",
    "        await browser.close()\n",
    "\n",
    "    # Parse med BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #job_posts = soup.select(\"a.cursor-pointer[onclick^='location.href']\")\n",
    "    \n",
    "    return soup \n",
    "\n",
    "\n",
    "# Kör async-funktionen i Jupyter\n",
    "soup = await scrape_combitech_jobs()\n",
    "job_posts = soup.select(\"div.block.w-full.mb-4.md\\\\:pb-0.md\\\\:mb-0.lg\\\\:pb-4\")\n",
    "print(len(job_posts))\n",
    "job_posts[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ec1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_combitech = job_data\n",
    "\n",
    "for job_post in job_posts: \n",
    "\n",
    "    # job_title\n",
    "    tag_title = job_post.select_one(\"#job-title\")\n",
    "    job_title = tag_title.get_text(strip=True) if tag_title else \"\"\n",
    "\n",
    "    # Job area\n",
    "    tag_area = job_post.select_one(\"#job-type\")\n",
    "    area = tag_area.get(\"data-value\", \"\").strip() if tag_area else \"\"\n",
    "\n",
    "    # Deadline (plocka text och ta bort prefix)\n",
    "    tag_due_date = job_post.select_one(\"h5.font-normal\")\n",
    "    due_date = \"\"\n",
    "    if tag_due_date:\n",
    "        txt = tag_due_date.get_text(strip=True)\n",
    "        if \"Sista ansökningsdag:\" in txt:\n",
    "            due_date = txt.replace(\"Sista ansökningsdag:\", \"\").strip()\n",
    "\n",
    "    # work_location\n",
    "    tag_location = job_post.select_one(\"#job-locations\")\n",
    "    work_location = tag_location.get_text(strip=True) if tag_location else \"\"\n",
    "\n",
    "    # link \n",
    "    tag_link = job_post.select_one(\"a.cursor-pointer\")\n",
    "    link = 'https://www.combitech.se' + tag_link.get(\"onclick\", \"\").replace(\"location.href=\", \"\").replace(\"'\", \"\") if tag_link else \"\"\n",
    "\n",
    "    job_data_combitech.loc[len(job_data_combitech)] = ['Combitech', None, job_title, area, None, None, None, None, due_date, work_location, work_type, link]\n",
    "job_data_combitech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2477b1",
   "metadata": {},
   "source": [
    "# Emagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://portal-api.emagine.org/api/JobAds/Search\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Referer\": \"https://portal.emagine.org/\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"skipCount\": 0,\n",
    "    \"maxResultCount\": 1000,\n",
    "    \"sorting\": \"CreationTime desc\",\n",
    "    \"filter\": {\n",
    "        \"isPartTime\": None,\n",
    "        \"textFilters\": [],\n",
    "        \"workLocationTypes\": [],\n",
    "        \"workLocations\": [{\"countryId\": \"SE\", \"city\": \"\", \"region\": \"\"}],\n",
    "        \"professionalRolesIds\": [],\n",
    "        \"consultantSeniorities\": [],\n",
    "        \"languageProficiencies\": [],\n",
    "        \"industriesIds\": [],\n",
    "        \"recordIdsToExclude\": []\n",
    "    },\n",
    "    \"supportedLanguageId\": \"EN\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "data = response.json()\n",
    "\n",
    "# alla annonser\n",
    "job_posts = data[\"items\"]\n",
    "print('Number of job posts:', len(job_posts))\n",
    "print('Format job post:\\n')\n",
    "job_posts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_emagine = job_data\n",
    "\n",
    "\n",
    "\n",
    "# Extract jobs\n",
    "for job in job_posts:\n",
    "    website = 'Emagine'\n",
    "    id = job['id']\n",
    "    job_title = job[\"title\"]\n",
    "    \n",
    "    try: \n",
    "        area = job[\"area\"][\"name\"]\n",
    "    except: \n",
    "        area = None\n",
    "\n",
    "    created = None \n",
    "    start_date = job[\"startDate\"]\n",
    "    end_date = None \n",
    "    duration = job[\"duration\"]\n",
    "    due_date = job['applicationDate']\n",
    "\n",
    "    work_location = job[\"jobAdWorkLocation\"][\"city\"]\n",
    "    work_type = job[\"jobAdWorkLocation\"][\"workLocationType\"]\n",
    "    link = f'https://portal.emagine.org/jobs/{id}/{slugify_title_for_link(job_title)}' \n",
    "\n",
    "    job_data_emagine.loc[len(job_data_emagine)] = [website, id, job_title, area, created, start_date, end_date, duration, due_date, work_location, work_type, link]\n",
    "job_data_emagine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b478e0c",
   "metadata": {},
   "source": [
    "# Ework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86541076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://app.verama.com/api/public/job-requests\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\",\n",
    "    \"Referer\": \"https://app.verama.com/sv/job-requests\",\n",
    "    \"x-frontend-version\": \"a4c15af0\",\n",
    "    \"x-session\": \"a9b80196-b28a-42a3-a83f-c1059ef946af\"\n",
    "}\n",
    "\n",
    "# Parametrar för att hämta alla jobb (storlek 100)\n",
    "params = {\n",
    "    \"page\": 0,\n",
    "    \"size\": 1000,  # hämta upp till 100 jobb\n",
    "    \"sort\": \"firstDayOfApplications,DESC\",\n",
    "    \"location.country\": \"Sweden\",\n",
    "    \"location.countryCode\": \"SWE\",\n",
    "    \"location.suggestedPhoneCode\": \"SE\",\n",
    "    \"location.locationId\": \"here:cm:namedplace:20298368\",\n",
    "    \"location.id\": \"NaN\",\n",
    "    \"location.signature\": \"\",\n",
    "    \"dedicated\": \"false\",\n",
    "    \"favouritesOnly\": \"false\",\n",
    "    \"recommendedOnly\": \"false\",\n",
    "    \"query\": \"\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "print(\"Status code:\", response.status_code)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# alla annonser\n",
    "job_posts = data[\"content\"]\n",
    "print('Number of job posts:', len(job_posts))\n",
    "print('Format job post:\\n')\n",
    "job_posts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_ework = job_data\n",
    "\n",
    "for job in job_posts: \n",
    "    website = 'Ework'\n",
    "    id = job['id']\n",
    "    job_title = job['title']\n",
    "    \n",
    "    area = ''\n",
    "    try: \n",
    "        for skills_dict in job['skills']:\n",
    "            skill = skills_dict['skill']['name']\n",
    "            area += f'{skill}, ' \n",
    "        area = area.strip(', ')\n",
    "    except: \n",
    "        area = None \n",
    "    \n",
    "    \n",
    "    created = job['createdDate']\n",
    "    start_date = job['startDate']\n",
    "    end_date = job['endDate']\n",
    "    duration = None \n",
    "    due_date = job['lastDayOfApplications']\n",
    "\n",
    "    work_location = ''\n",
    "    try:  \n",
    "        for location_dict in job['locations']:\n",
    "            location = location_dict['city']\n",
    "            work_location += f'{location}, '\n",
    "        work_location = work_location.strip(', ')\n",
    "    except: \n",
    "        work_location = None \n",
    "\n",
    "    work_type = ''\n",
    "    try: \n",
    "        remoteness = job['remoteness']\n",
    "        if remoteness == 0: \n",
    "            work_type = 'På plats'\n",
    "        elif remoteness == 100: \n",
    "            work_type = 'Remote'\n",
    "        else: \n",
    "            work_type = 'Hybrid'\n",
    "    except: \n",
    "        work_type = None\n",
    "\n",
    "    link = f'https://app.verama.com/sv/job-requests/{id}'\n",
    "\n",
    "\n",
    "\n",
    "    job_data_ework.loc[len(job_data_ework)] = [website, id, job_title, area, created, start_date, end_date, duration, due_date, work_location, work_type, link]\n",
    "job_data_ework\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544094",
   "metadata": {},
   "source": [
    "# Levigo \n",
    "(Inga uppdrag ute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d618eb0",
   "metadata": {},
   "source": [
    "# Nikita \n",
    "Hemsida som renderar innehållet via JavaScript efter att själva HTML:en har laddats. I detta fall hittar man inte hittar uppdragen i Fetch/XHR i nätverksinspektionen – själva jobblistan hämtas inte via ett öppet API som returnerar JSON, utan genereras dynamiskt i webbläsaren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cd144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Jupyter kan du köra async direkt med \"await\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def scrape_html_website():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://www.nikita.se/lediga-uppdrag/\")\n",
    "        await page.wait_for_timeout(2000)  # ge JS tid att ladda\n",
    "        html = await page.content()\n",
    "        await browser.close()\n",
    "\n",
    "    # Parse med BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #job_posts = soup.select(\"a.cursor-pointer[onclick^='location.href']\")\n",
    "    \n",
    "    return soup \n",
    "\n",
    "\n",
    "# Kör async-funktionen i Jupyter\n",
    "soup = await scrape_html_website()\n",
    "\n",
    "#job_posts = soup.select(\"div.block.w-full.mb-4.md\\\\:pb-0.md\\\\:mb-0.lg\\\\:pb-4\")\n",
    "job_posts = soup.select(\"li.open-position-item.opened\")\n",
    "print('Number of job posts:', len(job_posts))\n",
    "print('Format job post:\\n')\n",
    "job_posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_nikita = job_data\n",
    "\n",
    "for job in job_posts:\n",
    "    website = 'Nikita'\n",
    "    id = None \n",
    "    tag_title = job.select_one(\"span.open-position-title\")\n",
    "    job_title = tag_title.get_text(strip=True) if tag_title else \"\"\n",
    "    area = None \n",
    "\n",
    "    tag_created_day = job.select_one(\"span.open-position-date-day\")\n",
    "    tag_created_month = job.select_one(\"span.open-position-date-month\")\n",
    "    created_day = tag_created_day.get_text(strip=True) if tag_created_day else \"\"\n",
    "    created_month = tag_created_month.get_text(strip=True) if tag_created_month else \"\"\n",
    "    created_year = datetime.today().year\n",
    "    created_str = f'{created_day} {created_month} {created_year}'\n",
    "    date_obj = datetime.strptime(created_str, \"%d %b %Y\")\n",
    "    created = date_obj.strftime(\"%Y-%m-%d\")\n",
    "    # Format as yyyy-mm-dd\n",
    "\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    duration = None\n",
    "    due_date = None \n",
    "\n",
    "    work_location = None\n",
    "    work_type = None \n",
    "    tag_link = job.select_one(\"a.open-position-list-link\")\n",
    "    link = tag_link.get(\"onclick\", \"\").replace(\"href=\", \"\").replace(\"'\", \"\") if tag_link else \"\"\n",
    "\n",
    "    job_data_nikita.loc[len(job_data_nikita)] = [website, id, job_title, area, created, start_date, end_date, duration, due_date, work_location, work_type, link]\n",
    "job_data_nikita\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4bddc",
   "metadata": {},
   "source": [
    "# Regent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Jupyter kan du köra async direkt med \"await\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def scrape_html_website():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://regent.se/uppdrag/\")\n",
    "        await page.wait_for_timeout(2000)  # ge JS tid att ladda\n",
    "        html = await page.content()\n",
    "        await browser.close()\n",
    "\n",
    "    # Parse med BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #job_posts = soup.select(\"a.cursor-pointer[onclick^='location.href']\")\n",
    "    \n",
    "    return soup \n",
    "\n",
    "\n",
    "# Kör async-funktionen i Jupyter\n",
    "soup = await scrape_html_website()\n",
    "job_posts = soup.select(\"div.assignment-item\")\n",
    "print('Number of job posts:', len(job_posts))\n",
    "print('Format job post:\\n')\n",
    "job_posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_regent = job_data\n",
    "\n",
    "for job in job_posts:\n",
    "\n",
    "    website = 'Regent'\n",
    "    id = None \n",
    "    tag_title = job.select_one(\"a.blue > strong\")\n",
    "    job_title = tag_title.get_text(strip=True) if tag_title else \"\"\n",
    "    tag_area = job.select_one(\"div.summary\")\n",
    "    area = tag_area.get_text(strip=True) if tag_area else \"\"\n",
    "\n",
    "    created = None\n",
    "\n",
    "    div_start_date = job.find(\"strong\", string=\"Startdatum:\").find_next_sibling(\"div\")\n",
    "    start_date = div_start_date.get_text(strip=True) if div_start_date else \"\"\n",
    "    \n",
    "    div_end_date = job.find(\"strong\", string=\"Slutdatum:\").find_next_sibling(\"div\")\n",
    "    end_date = div_end_date.get_text(strip=True) if div_end_date else \"\"\n",
    "    \n",
    "    duration = None\n",
    "    due_date = None \n",
    "\n",
    "    div_location = job.find(\"strong\", string=\"Ort:\").find_next_sibling(\"div\")\n",
    "    work_location = div_location.get_text(strip=True) if div_location else \"\"\n",
    "\n",
    "    work_type = None \n",
    "    tag_link = job.select_one(\"a.btn.btn-warning.visa-desktop\")\n",
    " \n",
    "    link = 'https://regent.se' + tag_link.get(\"href\") if tag_link else \"\"\n",
    "   \n",
    "    job_data_regent.loc[len(job_data_regent)] = [website, id, job_title, area, created, start_date, end_date, duration, due_date, work_location, work_type, link]\n",
    "\n",
    "job_data_regent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9aa324",
   "metadata": {},
   "source": [
    "# Updraged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Jupyter kan du köra async direkt med \"await\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def scrape_html_website():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://upgraded.se/lediga-uppdrag/\")\n",
    "        await page.wait_for_timeout(3000)  # ge JS tid att ladda\n",
    "        html = await page.content()\n",
    "        await browser.close()\n",
    "\n",
    "    # Parse med BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Steg 1: hitta alla jobb\n",
    "    job_posts = soup.select(\"tr.konsultuppdrag__table-row\")\n",
    "    return job_posts\n",
    "\n",
    "# Kör async-funktionen i Jupyter\n",
    "job_posts = await scrape_html_website()\n",
    "print('Number of job posts:', len(job_posts))\n",
    "print('Format job post:\\n')\n",
    "job_posts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize DataFrame with standard columns\n",
    "job_data = pd.DataFrame(columns=['website', 'id', 'job_title', 'area', 'created', 'start_date', \n",
    "                                 'end_date', 'duration', 'due_date', 'work_location', 'work_type', 'link'])\n",
    "job_data_upgraded = job_data\n",
    "\n",
    "for job in job_posts:\n",
    "\n",
    "    website = 'Upgraded'\n",
    "    id = None  # not available in HTML\n",
    "    area = None\n",
    "    created = None\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    duration = None\n",
    "\n",
    "    tag_due_date = job.select_one(\"td.konsultuppdrag-column-3\")\n",
    "    due_date = tag_due_date.get_text(strip=True) if tag_due_date else None\n",
    "    \n",
    "\n",
    "    # Job title\n",
    "    tag_title = job.select_one(\"h5.entry-title\")\n",
    "    job_title = tag_title.get_text(strip=True) if tag_title else None\n",
    "\n",
    "    # Work location (city)\n",
    "    tag_info = job.select(\"span\")\n",
    "    info_list = []\n",
    "    work_location = None\n",
    "    for span in tag_info:\n",
    "        info = span.get_text(strip=True)\n",
    "        info_list.append(info)\n",
    "\n",
    "    id = info_list[0]\n",
    "    work_location = info_list[2]\n",
    "    work_type = info_list[4]\n",
    "    area = info_list[6]\n",
    "\n",
    "    # Link\n",
    "    tag_link = job.select_one(\"a[href^='https://upgraded.se/konsultuppdrag/']\")\n",
    "    link = tag_link.get(\"href\") if tag_link else None\n",
    "\n",
    "    # Append row to DataFrame\n",
    "    job_data_upgraded.loc[len(job_data_upgraded)] = [\n",
    "        website, id, job_title, area, created, start_date, end_date, duration,\n",
    "        due_date, work_location, work_type, link\n",
    "    ]\n",
    " \n",
    "\n",
    "job_data_upgraded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
