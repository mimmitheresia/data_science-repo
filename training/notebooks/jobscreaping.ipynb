{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1c3db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://example.com\")\n",
    "print(r.status_code)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# install package direcly in notebook: %pip install requests-html\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742e244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def most_frequent_terms(df, column, top_n=10):\n",
    "    \"\"\"\n",
    "    Return the most frequent terms from a text column in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        column (str): Column name containing text.\n",
    "        top_n (int): Number of most frequent terms to return.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with term counts.\n",
    "    \"\"\"\n",
    "    # Join all text in column into one big string\n",
    "    text = \" \".join(df[column].astype(str).tolist())\n",
    "    \n",
    "    # Tokenize: lowercase words, only keep a–z characters\n",
    "    tokens = re.findall(r\"\\b[a-zA-ZåäöÅÄÖ]+\\b\", text.lower())\n",
    "    \n",
    "    # Count terms\n",
    "    counter = Counter(tokens)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    most_common = counter.most_common(top_n)\n",
    "    return pd.DataFrame(most_common, columns=[\"term\", \"count\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>site_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>area</th>\n",
       "      <th>created</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>due_date</th>\n",
       "      <th>work_location</th>\n",
       "      <th>work_type</th>\n",
       "      <th>link</th>\n",
       "      <th>raw_payload</th>\n",
       "      <th>ingestion_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Society</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afry</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aliant</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Combitech</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emagine</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ework</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nikita</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Regent</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Upgraded</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>38</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        site  site_id  job_title  area  created  start_date  end_date  \\\n",
       "0  A Society       95         95    95       95          85         0   \n",
       "1       Afry       78         78    78        0           0         0   \n",
       "2     Aliant        7          7     0        7           0         0   \n",
       "3  Combitech       29         29    29        0           0         0   \n",
       "4    Emagine       49         49    48        0          46         0   \n",
       "5      Ework      108        108     5      108         108       108   \n",
       "6     Nikita       20         20     0       20           0         0   \n",
       "7     Regent       26         26    26        0          26        26   \n",
       "8   Upgraded       90         90    89        0           0         0   \n",
       "\n",
       "   duration  due_date  work_location  work_type  link  raw_payload  \\\n",
       "0         0        95             95         95    95           95   \n",
       "1         0        78             74          0    78           78   \n",
       "2         0         7              7          5     7            7   \n",
       "3         0        29             29          0    29           29   \n",
       "4        49         0             35         49    49           49   \n",
       "5         0       108            108        108   108          108   \n",
       "6         0         0              0          0    20           20   \n",
       "7         0         0             26          0    26           26   \n",
       "8         0        90             88         38    90           90   \n",
       "\n",
       "   ingestion_ts  \n",
       "0            95  \n",
       "1            78  \n",
       "2             7  \n",
       "3            29  \n",
       "4            49  \n",
       "5           108  \n",
       "6            20  \n",
       "7            26  \n",
       "8            90  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_data = pd.read_csv('../data/bronze/jobs.csv', index_col=0)\n",
    "bronze_group = bronze_data.groupby(by=['site']).count().reset_index() \n",
    "bronze_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbb0079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = most_frequent_terms(bronze_data, \"job_title\", top_n=100)\n",
    "df.to_csv('../data/most_frequent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef754407",
   "metadata": {},
   "source": [
    "# Afry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a360b4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afry > Response: 200\n",
      "Afry > Nmr of scraped adds: 69\n",
      "Afry > Parsing bronze data: 1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "from src.scrapers.afry_scraper import AfryScraper\n",
    "s = AfryScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43f825",
   "metadata": {},
   "source": [
    "# Aliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2738342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliant > Response: 200\n",
      "Aliant > Nmr of scraped adds: 7\n",
      "Aliant > Parsing bronze data: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "from src.scrapers.aliant_scraper import AliantScraper\n",
    "s = AliantScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de53a36",
   "metadata": {},
   "source": [
    "# Asociety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03886cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Society > Response: 200\n",
      "A Society > Nmr of scraped adds: 95\n",
      "A Society > Parsing bronze data: 2\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.asociety_scraper import ASocietyScraper\n",
    "s = ASocietyScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997fee",
   "metadata": {},
   "source": [
    "# Combitech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd86c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combitech > Response: 200\n",
      "Combitech > Nmr of scraped adds: 30\n",
      "Combitech > Parsing bronze data: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "from src.scrapers.combitech_scraper import CombitechScraper\n",
    "s = CombitechScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2477b1",
   "metadata": {},
   "source": [
    "# Emagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf0068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emagine > Response: 200\n",
      "Emagine > Nmr of scraped adds: 46\n",
      "Emagine > Parsing bronze data: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.emagine_scraper import EmagineScraper\n",
    "s = EmagineScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b478e0c",
   "metadata": {},
   "source": [
    "# Ework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ework > Response: 200\n",
      "Ework > Nmr of scraped adds: 94\n",
      "Ework > Parsing bronze data: 1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.ework_scraper import EworkScraper\n",
    "s = EworkScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544094",
   "metadata": {},
   "source": [
    "# Levigo \n",
    "(Inga uppdrag ute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d618eb0",
   "metadata": {},
   "source": [
    "# Nikita \n",
    "Hemsida som renderar innehållet via JavaScript efter att själva HTML:en har laddats. I detta fall hittar man inte hittar uppdragen i Fetch/XHR i nätverksinspektionen – själva jobblistan hämtas inte via ett öppet API som returnerar JSON, utan genereras dynamiskt i webbläsaren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nikita > Response: 200\n",
      "Nikita > Nmr of scraped adds: 20\n",
      "Nikita > Parsing bronze data: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.nikita_scraper import NikitaScraper\n",
    "s = NikitaScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4bddc",
   "metadata": {},
   "source": [
    "# Regent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regent > Response: 200\n",
      "Regent > Nmr of scraped adds: 28\n",
      "Regent > Parsing bronze data: 1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.regent_scraper import RegentScraper\n",
    "s = RegentScraper()\n",
    "\n",
    "response = s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9aa324",
   "metadata": {},
   "source": [
    "# Updraged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgraded > Status code: 200\n",
      "Upgraded > Nmr of scraped adds: 78\n",
      "Upgraded > Parsing bronze data: 1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "\n",
    "from src.scrapers.upgraded_scraper import UpgradedScraper\n",
    "s = UpgradedScraper()\n",
    "\n",
    "response = await s.request_status()\n",
    "scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "old_bronze_data = load_local_data()\n",
    "\n",
    "new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "unload_local_data(updated_bronze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160207e",
   "metadata": {},
   "source": [
    "# Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bb21c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afry > Response: 200\n",
      "Afry > Nmr of scraped adds: 69\n",
      "Afry > Parsing bronze data: 0\n",
      "Aliant > Response: 200\n",
      "Aliant > Nmr of scraped adds: 7\n",
      "Aliant > Parsing bronze data: 0\n",
      "A Society > Response: 200\n",
      "A Society > Nmr of scraped adds: 95\n",
      "A Society > Parsing bronze data: 0\n",
      "Combitech > Response: 200\n",
      "Combitech > Nmr of scraped adds: 30\n",
      "Combitech > Parsing bronze data: 0\n",
      "Emagine > Response: 200\n",
      "Emagine > Nmr of scraped adds: 46\n",
      "Emagine > Parsing bronze data: 0\n",
      "Ework > Response: 200\n",
      "Ework > Nmr of scraped adds: 94\n",
      "Ework > Parsing bronze data: 0\n",
      "Nikita > Response: 200\n",
      "Nikita > Nmr of scraped adds: 20\n",
      "Nikita > Parsing bronze data: 0\n",
      "Regent > Response: 200\n",
      "Regent > Nmr of scraped adds: 29\n",
      "Regent > Parsing bronze data: 1\n",
      "Upgraded > Status code: 200\n",
      "Upgraded > Nmr of scraped adds: 78\n",
      "Upgraded > Parsing bronze data: 0\n",
      "Total number of new added jobs: 1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "from src.scrapers.afry_scraper import AfryScraper\n",
    "from src.scrapers.aliant_scraper import AliantScraper\n",
    "from src.scrapers.asociety_scraper import ASocietyScraper\n",
    "from src.scrapers.combitech_scraper import CombitechScraper\n",
    "from src.scrapers.emagine_scraper import EmagineScraper\n",
    "from src.scrapers.ework_scraper import EworkScraper\n",
    "from src.scrapers.nikita_scraper import NikitaScraper\n",
    "from src.scrapers.regent_scraper import RegentScraper\n",
    "from src.scrapers.upgraded_scraper import UpgradedScraper\n",
    "\n",
    "\n",
    "nr_ads_pre = len(pd.read_csv('../data/bronze/jobs.csv'))\n",
    "\n",
    "scrapers = [AfryScraper(), AliantScraper(), ASocietyScraper(), CombitechScraper(), EmagineScraper(), EworkScraper(), NikitaScraper(), RegentScraper(), UpgradedScraper()]\n",
    "for s in scrapers:\n",
    "    if s.site == 'Upgraded': \n",
    "        response = await s.request_status()\n",
    "    else: \n",
    "        response = s.request_status()\n",
    "\n",
    "    scraped_raw_data = s.return_raw_job_posts_data(response)\n",
    "    old_bronze_data = load_local_data()\n",
    "\n",
    "    new_raw_data = s.return_new_rows(new_data=scraped_raw_data, old_data=old_bronze_data)\n",
    "    new_bronze_data = s.parse_bronze_data(new_raw_data)\n",
    "    updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "    unload_local_data(updated_bronze_data)\n",
    "\n",
    "nr_ads_post = len(pd.read_csv('../data/bronze/jobs.csv'))\n",
    "print('Total number of new added jobs:', nr_ads_post-nr_ads_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfcd43",
   "metadata": {},
   "source": [
    "# Bronze table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "008c614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "bronze_data = load_local_data()\n",
    "print(len(bronze_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
