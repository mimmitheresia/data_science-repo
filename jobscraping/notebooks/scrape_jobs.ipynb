{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://example.com\")\n",
    "print(r.status_code)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# install package direcly in notebook: %pip install requests-html\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages \n",
    "%pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def most_frequent_terms(df, column, top_n=10):\n",
    "    \"\"\"\n",
    "    Return the most frequent terms from a text column in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        column (str): Column name containing text.\n",
    "        top_n (int): Number of most frequent terms to return.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with term counts.\n",
    "    \"\"\"\n",
    "    # Join all text in column into one big string\n",
    "    text = \" \".join(df[column].astype(str).tolist())\n",
    "    \n",
    "    # Tokenize: lowercase words, only keep a–z characters\n",
    "    tokens = re.findall(r\"\\b[a-zA-ZåäöÅÄÖ]+\\b\", text.lower())\n",
    "    \n",
    "    # Count terms\n",
    "    counter = Counter(tokens)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    most_common = counter.most_common(top_n)\n",
    "    return pd.DataFrame(most_common, columns=[\"term\", \"count\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_data = pd.read_csv('../data/bronze/jobs.csv', index_col=0)\n",
    "bronze_group = bronze_data.groupby(by=['site']).count().reset_index() \n",
    "bronze_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = most_frequent_terms(bronze_data, \"job_title\", top_n=100)\n",
    "df.to_csv('../data/most_frequent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160207e",
   "metadata": {},
   "source": [
    "# Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb21c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afry > Response: 200\n",
      "Afry > Nmr of scraped adds: 81\n",
      "Afry > Parsing bronze data: 0\n",
      "Aliant > Response: 200\n",
      "Aliant > Nmr of scraped adds: 10\n",
      "Aliant > Parsing bronze data: 0\n",
      "A Society > Response: 200\n",
      "A Society > Nmr of scraped adds: 113\n",
      "A Society > Parsing bronze data: 0\n",
      "Combitech > Response: 200\n",
      "Combitech > Nmr of scraped adds: 34\n",
      "Combitech > Parsing bronze data: 0\n",
      "Emagine > Response: 200\n",
      "Emagine > Nmr of scraped adds: 44\n",
      "Emagine > Parsing bronze data: 0\n",
      "Ework > Response: 200\n",
      "Ework > Nmr of scraped adds: 87\n",
      "Ework > Parsing bronze data: 0\n",
      "Nikita > Response: 200\n",
      "Nikita > Nmr of scraped adds: 20\n",
      "Nikita > Parsing bronze data: 0\n",
      "Regent > Response: 200\n",
      "Regent > Nmr of scraped adds: 32\n",
      "Regent > Parsing bronze data: 0\n",
      "Upgraded > Status code: 200\n",
      "Upgraded > Nmr of scraped adds: 75\n",
      "Upgraded > Parsing bronze data: 0\n",
      "Total number of new added jobs: 0\n",
      "Total number of new added jobs_payloads: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) # lägg till training i path\n",
    "from src.data_loader import load_local_data, unload_local_data, load_local_dict, unload_local_dict\n",
    "from src.scrapers.abstract_scraper import AbstractScraper\n",
    "from src.scrapers.afry_scraper import AfryScraper\n",
    "from src.scrapers.aliant_scraper import AliantScraper\n",
    "from src.scrapers.asociety_scraper import ASocietyScraper\n",
    "from src.scrapers.combitech_scraper import CombitechScraper\n",
    "from src.scrapers.emagine_scraper import EmagineScraper\n",
    "from src.scrapers.ework_scraper import EworkScraper\n",
    "from src.scrapers.nikita_scraper import NikitaScraper\n",
    "from src.scrapers.regent_scraper import RegentScraper\n",
    "from src.scrapers.upgraded_scraper import UpgradedScraper\n",
    "\n",
    "nr_payload_pre = len(load_local_dict())\n",
    "nr_ads_pre = len(pd.read_csv('../data/bronze/jobs.csv'))\n",
    "\n",
    "scrapers = [AfryScraper(), AliantScraper(), ASocietyScraper(), CombitechScraper(), EmagineScraper(), EworkScraper(), NikitaScraper(), RegentScraper(), UpgradedScraper()]\n",
    "#scrapers = [AfryScraper()]\n",
    "for s in scrapers:\n",
    "    if s.site == 'Upgraded': \n",
    "        response = await s.request_status()\n",
    "    else: \n",
    "        response = s.request_status()\n",
    "\n",
    "    scraped_payload_dict = s.return_raw_job_posts_data(response)\n",
    "    old_payload_dict = load_local_dict()\n",
    "    old_bronze_data = load_local_data()\n",
    "    \n",
    "    new_payload_dict = s.return_new_ads(new_dict=scraped_payload_dict, old_dict=old_payload_dict)\n",
    "    new_bronze_data = s.parse_bronze_data(new_payload_dict)\n",
    "\n",
    "    updated_payload_dict = s.concat_dicts(new_payload_dict, old_payload_dict)\n",
    "    updated_bronze_data = s.concat_new_rows(new_bronze_data, old_bronze_data)\n",
    "    unload_local_dict(updated_payload_dict)\n",
    "    unload_local_data(updated_bronze_data)\n",
    "\n",
    "\n",
    "nr_payload_post = len(load_local_dict())\n",
    "nr_ads_post = len(pd.read_csv('../data/bronze/jobs.csv'))\n",
    "print('Total number of new added jobs:', nr_ads_post-nr_ads_pre)\n",
    "print('Total number of new added jobs_payloads:', nr_payload_post-nr_payload_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfcd43",
   "metadata": {},
   "source": [
    "# Bronze table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.data_loader import load_local_data, unload_local_data\n",
    "bronze_data = load_local_data()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-ml-project)",
   "language": "python",
   "name": "my-ml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
